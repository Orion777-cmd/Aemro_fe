# Aemro (áŠ áˆáˆ®) - Your AI Study Buddy

Aemro is your AI study buddy designed for students. Upload your textbooks and study materials, and Aemro will help you learn by directly referencing your preferred textbooks. Built with Next.js, React, TypeScript, and TailwindCSS.

## Features

- ğŸ“š **Study Buddy**: AI assistant that helps you learn by referencing your textbooks
- ğŸ’¬ **Real-time Chat**: Stream AI responses with a beautiful interface
- ğŸ“„ **Textbook Upload**: Upload PDF, TXT, or MD textbooks and study materials
- ğŸ¯ **Direct References**: AI directly quotes and references your preferred textbooks
- ğŸ¨ **Premium Design**: Black & gold theme with smooth animations
- ğŸ’¾ **Persistent Storage**: Messages and textbooks saved in localStorage
- ğŸ“± **Responsive**: Works seamlessly on desktop and mobile devices
- âœ¨ **Markdown Support**: Rich text rendering for AI responses

## Tech Stack

- **Next.js 14** (App Router)
- **React 18**
- **TypeScript**
- **TailwindCSS**
- **Server Actions** for backend logic
- **react-markdown** for markdown rendering

## Setup Instructions

### 1. Install Dependencies

```bash
npm install
```

### 2. Environment Variables

Create a `.env.local` file in the root directory:

```env
BACKEND_API_URL=http://localhost:8000
```

**Note**: 
- Set `BACKEND_API_URL` to your LangGraph backend API URL
- If not set, defaults to `http://localhost:8000`
- If the backend is unreachable, the application will use mock responses for testing

### 3. Run Development Server

```bash
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) in your browser.

### 4. Build for Production

```bash
npm run build
npm start
```

## Project Structure

```
frontend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ actions/           # Server Actions
â”‚   â”‚   â”œâ”€â”€ chat.ts       # Chat completion logic
â”‚   â”‚   â””â”€â”€ documents.ts  # Document upload/list logic
â”‚   â”œâ”€â”€ components/        # React Components
â”‚   â”‚   â”œâ”€â”€ Header.tsx
â”‚   â”‚   â”œâ”€â”€ Sidebar.tsx
â”‚   â”‚   â”œâ”€â”€ ChatWindow.tsx
â”‚   â”‚   â”œâ”€â”€ MessageList.tsx
â”‚   â”‚   â”œâ”€â”€ MessageItem.tsx
â”‚   â”‚   â”œâ”€â”€ ChatInput.tsx
â”‚   â”‚   â””â”€â”€ DocumentPicker.tsx
â”‚   â”œâ”€â”€ lib/              # Utilities
â”‚   â”‚   â”œâ”€â”€ utils.ts      # localStorage, formatting helpers
â”‚   â”‚   â””â”€â”€ types.ts      # TypeScript types
â”‚   â”œâ”€â”€ globals.css       # Global styles
â”‚   â”œâ”€â”€ layout.tsx        # Root layout
â”‚   â””â”€â”€ page.tsx          # Main page
â”œâ”€â”€ uploads/              # Uploaded documents (created automatically)
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ tailwind.config.ts
â””â”€â”€ next.config.js
```

## Architecture

### Frontend

- **State Management**: React hooks (`useState`, `useEffect`) with localStorage persistence
- **Components**: Modular, reusable components following single responsibility principle
- **Styling**: TailwindCSS with custom black & gold theme
- **Streaming**: Server Actions with async generators for real-time response streaming

### Backend

- **Server Actions**: Next.js Server Actions for API logic
- **File Storage**: Local filesystem (`uploads/` directory)
- **Document Processing**: Supports PDF, TXT, and MD files
- **AI Integration**: LangGraph backend API with streaming support
- **Backend Communication**: RESTful API calls to LangGraph backend

### Data Flow

1. User sends a message â†’ `ChatInput` component
2. Message added to state â†’ `page.tsx`
3. Server Action called â†’ `chat.ts` with selected document IDs
4. Documents loaded â†’ `documents.ts` reads file contents
5. Context prepared â†’ Combined with user message
6. AI API called â†’ OpenAI API or mock response
7. Streamed response â†’ Chunks yielded back to client
8. UI updates â†’ Real-time message rendering

## Backend Configuration

### Backend API Setup

Configure your LangGraph backend URL in `.env.local`:

```env
BACKEND_API_URL=http://localhost:8000
```

**Backend API Requirements:**
- Endpoint: `POST /api/chat`
- Expected request format:
  ```json
  {
    "messages": [
      { "role": "user", "content": "..." },
      { "role": "assistant", "content": "..." }
    ],
    "document_ids": ["doc1", "doc2"],
    "stream": true
  }
  ```
- Response: Server-Sent Events (SSE) stream with text chunks
- The backend should handle document processing via LangGraph

The application will automatically:
- Connect to the backend if configured
- Fall back to mock responses if backend is unreachable
- Display appropriate error messages if connection fails

## Usage

1. **Upload Your Textbooks**: Click or drag your textbook files (PDF, TXT, MD) into the document picker
2. **Select Your Textbook**: Check the boxes next to the textbooks you want Aemro to reference
3. **Ask Questions**: Type questions about your course material and press Enter (or Shift+Enter for newline)
4. **Get Textbook-Based Answers**: Aemro will answer by directly referencing your selected textbooks
5. **Study Efficiently**: Use Aemro as your study buddy to understand concepts, get explanations, and review material
6. **Clear Chat**: Use the "Clear Chat" button to reset conversation history

## Code Quality

- âœ… Strong TypeScript typing throughout
- âœ… Reusable, modular components
- âœ… Clean folder structure
- âœ… No dead code or TODO placeholders
- âœ… Production-ready error handling
- âœ… Responsive design

## Bonus Features Implemented

- âœ… Drag & drop file upload
- âœ… Toast notifications (via browser alerts for errors)
- âœ… Dark scrollbar styling

## Browser Support

- Chrome/Edge (latest)
- Firefox (latest)
- Safari (latest)

## License

Private project - All rights reserved.
# Aemro_fe
